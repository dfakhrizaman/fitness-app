import Head from 'next/head'
import { Box, Group, SimpleGrid, Text } from "@mantine/core";
import Webcam from "react-webcam";
import * as posenet from "@tensorflow-models/posenet";
import { CanvasHTMLAttributes, Key, useEffect, useRef, useState } from "react";
import * as tf from "@tensorflow/tfjs";
import { drawKeypoints, drawSkeleton } from "../utils/utilities";

export interface Keypoints {
  score: number;
  part: string;
  position: Position;
}

export interface Position {
  x: number;
  y: number;
}

export default function Home() {
  const webcamRef = useRef<Webcam>(null);
  const canvasRef = useRef(null);
  const [model, setModel] = useState<posenet.PoseNet | null>(null);
  const [keypoints, setKeypoints] = useState<Keypoints[] | null>(null);
  const [currentPose, setCurrentPose] = useState<{
    keypoints: Keypoints[];
    score: number;
  } | null>(null);
  const [score, setScore] = useState(0);
  const [counter, setCounter] = useState(0);

  useEffect(() => {
    async function loadModel() {
      const net = await posenet.load({
        architecture: "MobileNetV1",
        outputStride: 16,
        inputResolution: { width: 640, height: 480 },
        multiplier: 0.5,
      });
      setModel(net);
    }
    console.log("Initialize tensorflow", tf.getBackend());
    loadModel();
  }, []);

  const drawCanvas = (
    pose: posenet.Pose,
    video: HTMLVideoElement,
    videoWidth: number,
    videoHeight: number,
    canvas: any
  ) => {
    const ctx = canvas.current.getContext("2d");
    canvas.current.width = videoWidth;
    canvas.current.height = videoHeight;

    drawKeypoints(pose["keypoints"], 0.5, ctx);
    drawSkeleton(pose["keypoints"], 0.5, ctx);
  };

  const detect = async (net: posenet.PoseNet) => {
    if (
      typeof webcamRef.current !== "undefined" &&
      webcamRef.current &&
      webcamRef.current.video?.readyState === 4
    ) {
      // Get Properties
      const video = webcamRef.current.video;
      const videoWidth = webcamRef.current.video.videoWidth;
      const videoHeight = webcamRef.current.video.videoHeight;

      // Set video dimensions
      webcamRef.current.video.width = videoWidth;
      webcamRef.current.video.height = videoHeight;
      setCounter((prevCounter) => prevCounter + 1);

      // Detection
      const pose = await net.estimateSinglePose(video);

      setCurrentPose(pose);

      // Render skeleton
      drawCanvas(pose, video, videoWidth, videoHeight, canvasRef);
    }
  };

  useEffect(() => {
    if (!model) return;

    // Detect keypoints every 100 milliseconds
    setInterval(() => {
      detect(model);
    }, 150);
  }, [model]);

  useEffect(() => {
    if (currentPose && counter % 5 === 0) {
      setKeypoints(currentPose.keypoints);
      setScore(currentPose.score);
      setCounter(0);
    }
  }, [counter]);

  return (
    <>
      <Head>
        <title>Fitness App</title>
        <meta name="description" content="Generated by create next app" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <link rel="icon" href="/favicon.ico" />
      </Head>
      <main>
        <Box>
          <Webcam
            ref={webcamRef}
            style={{ position: "absolute", width: 800, height: 600, zIndex: 9 }}
          />

          <canvas
            ref={canvasRef}
            style={{ position: "absolute", width: 800, height: 600, zIndex: 9 }}
          />
        </Box>

        <Box pt={630}>
          <Box>
            <Text>Overall Score: {score.toFixed(2)}</Text>
          </Box>
          <SimpleGrid cols={4}>
            {keypoints &&
              keypoints.map((point) => (
                <Box key={point.part} sx={{ width: 160 }}>
                  <Text>
                    {point.part}: {point.score.toFixed(2)}
                  </Text>
                </Box>
              ))}
          </SimpleGrid>
        </Box>
      </main>
    </>
  );
}
